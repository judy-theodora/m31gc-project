{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13c0ce62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import astropy.coordinates as coord\n",
    "import astropy.units as u\n",
    "from astropy.io import ascii\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bb1f627",
   "metadata": {},
   "outputs": [],
   "source": [
    "bounds = pickle.load(open('./pickle/bounds.pk','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9250ced1",
   "metadata": {},
   "outputs": [],
   "source": [
    "master_cat = pd.read_csv('./catdata/master_catalog_jan_2023.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1b631d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_files = ['cat1_50.pk','cat51_100.pk','cat101_150.pk','cat151_200.pk','cat201_235.pk',\n",
    "             'cat236_257.pk','cat258_279.pk','cat280_320.pk','cat321_360.pk','cat361_406.pk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "58d260ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "object_matches = pickle.load(open('./pickle/matches_delta006_crowding300.pk','rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80c58e8",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bce00fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open('./pickle/training_data_d006_c300.pk','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b12bed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_cat(field): # change to match-case\n",
    "    if field <= 50: to_load = cat_files[0]\n",
    "    elif field <= 100: to_load = cat_files[1]\n",
    "    elif field <= 150: to_load = cat_files[2]\n",
    "    elif field <= 200: to_load = cat_files[3]\n",
    "    elif field <= 235: to_load = cat_files[4]\n",
    "    elif field <= 257: to_load = cat_files[5]\n",
    "    elif field <= 279: to_load = cat_files[6]\n",
    "    elif field <= 320: to_load = cat_files[7]\n",
    "    elif field <= 360: to_load = cat_files[8]\n",
    "    elif field <= 406: to_load = cat_files[9]\n",
    "    print(f'Loading {to_load} ...')\n",
    "    catalogue = pickle.load(open(f'./pickle/{to_load}','rb'))\n",
    "    \n",
    "    return catalogue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742bb234",
   "metadata": {},
   "source": [
    "## Generate Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e1167494",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_data(matches):\n",
    "    cat = load_cat(1)\n",
    "    \n",
    "    columns = ['obj_id','class','i','g','di','dg','ra','dec','field','pdidx']\n",
    "    values = []\n",
    "    object_ids = []\n",
    "    \n",
    "    for field in matches: # iterate through each field ID\n",
    "        print(f'Working on {field}')\n",
    "        working_field = matches[field] # take the list of matches\n",
    "        if field not in cat: # load the correct catalogue\n",
    "            cat = load_cat(field)\n",
    "        for m in working_field: # iterate through each match and grab values from catalogues\n",
    "            obj_id = master_cat.loc[m[1]].ID\n",
    "            class_ = master_cat.loc[m[1]].CLASS #STR?\n",
    "            \n",
    "            if obj_id in object_ids: continue # if we've already added the object then skip\n",
    "            else: object_ids.append(obj_id)   # (due to duplicated)\n",
    "            \n",
    "            if class_ == 1: class_str = 'gc'\n",
    "            elif class_ == 4: class_str = 'galaxy'\n",
    "            elif class_ == 6: class_str = 'star'\n",
    "            else: continue # skip non-gc/gal/stars\n",
    "            \n",
    "            row = cat[field][m[0]]\n",
    "            ra = row['RA']\n",
    "            dec = row['Dec']\n",
    "            g = row['g']\n",
    "            i = row['i']\n",
    "            dg = row['dg']\n",
    "            di = row['di']\n",
    "            \n",
    "            values.append([obj_id,class_str,i,g,di,dg,ra,dec,field,m[0]])\n",
    "    \n",
    "    training_data_dict = dict(zip(columns,zip(*values)))\n",
    "    training_data_df = pd.DataFrame(training_data_dict)\n",
    "    return training_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e22bb9f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cat1_50.pk ...\n",
      "Working on 5\n",
      "Working on 11\n",
      "Working on 13\n",
      "Working on 14\n",
      "Working on 20\n",
      "Working on 22\n",
      "Working on 24\n",
      "Working on 25\n",
      "Working on 26\n",
      "Working on 30\n",
      "Working on 33\n",
      "Working on 35\n",
      "Working on 37\n",
      "Working on 43\n",
      "Working on 52\n",
      "Loading cat51_100.pk ...\n",
      "Working on 58\n",
      "Working on 62\n",
      "Working on 70\n",
      "Working on 80\n",
      "Working on 81\n",
      "Working on 82\n",
      "Working on 84\n",
      "Working on 85\n",
      "Working on 91\n",
      "Working on 92\n",
      "Working on 94\n",
      "Working on 95\n",
      "Working on 97\n",
      "Working on 102\n",
      "Loading cat101_150.pk ...\n",
      "Working on 111\n",
      "Working on 114\n",
      "Working on 124\n",
      "Working on 125\n",
      "Working on 126\n",
      "Working on 128\n",
      "Working on 138\n",
      "Working on 139\n",
      "Working on 142\n",
      "Working on 146\n",
      "Working on 148\n",
      "Working on 153\n",
      "Loading cat151_200.pk ...\n",
      "Working on 162\n",
      "Working on 165\n",
      "Working on 167\n",
      "Working on 169\n",
      "Working on 173\n",
      "Working on 180\n",
      "Working on 183\n",
      "Working on 184\n",
      "Working on 185\n",
      "Working on 186\n",
      "Working on 187\n",
      "Working on 188\n",
      "Working on 189\n",
      "Working on 196\n",
      "Working on 201\n",
      "Loading cat201_235.pk ...\n",
      "Working on 204\n",
      "Working on 205\n",
      "Working on 207\n",
      "Working on 208\n",
      "Working on 209\n",
      "Working on 210\n",
      "Working on 211\n",
      "Working on 212\n",
      "Working on 214\n",
      "Working on 220\n",
      "Working on 223\n",
      "Working on 224\n",
      "Working on 225\n",
      "Working on 227\n",
      "Working on 228\n",
      "Working on 229\n",
      "Working on 231\n",
      "Working on 232\n",
      "Working on 233\n",
      "Working on 234\n",
      "Working on 235\n",
      "Working on 238\n",
      "Loading cat236_257.pk ...\n",
      "Working on 240\n",
      "Working on 241\n",
      "Working on 243\n",
      "Working on 248\n",
      "Working on 249\n",
      "Working on 253\n",
      "Working on 254\n",
      "Working on 255\n",
      "Working on 256\n",
      "Working on 257\n",
      "Working on 261\n",
      "Loading cat258_279.pk ...\n",
      "Working on 263\n",
      "Working on 265\n",
      "Working on 266\n",
      "Working on 268\n",
      "Working on 269\n",
      "Working on 274\n",
      "Working on 275\n",
      "Working on 276\n",
      "Working on 277\n",
      "Working on 278\n",
      "Working on 279\n",
      "Working on 280\n",
      "Loading cat280_320.pk ...\n",
      "Working on 282\n",
      "Working on 285\n",
      "Working on 286\n",
      "Working on 287\n",
      "Working on 293\n",
      "Working on 294\n",
      "Working on 295\n",
      "Working on 296\n",
      "Working on 297\n",
      "Working on 301\n",
      "Working on 303\n",
      "Working on 304\n",
      "Working on 306\n",
      "Working on 307\n",
      "Working on 310\n",
      "Working on 316\n",
      "Working on 317\n",
      "Working on 319\n",
      "Working on 321\n",
      "Loading cat321_360.pk ...\n",
      "Working on 327\n",
      "Working on 328\n",
      "Working on 333\n",
      "Working on 334\n",
      "Working on 335\n",
      "Working on 336\n",
      "Working on 338\n",
      "Working on 339\n",
      "Working on 340\n",
      "Working on 341\n",
      "Working on 342\n",
      "Working on 347\n",
      "Working on 348\n",
      "Working on 351\n",
      "Working on 362\n",
      "Loading cat361_406.pk ...\n",
      "Working on 368\n",
      "Working on 375\n",
      "Working on 379\n",
      "Working on 390\n",
      "Working on 391\n",
      "Working on 392\n",
      "Working on 395\n",
      "Working on 398\n",
      "Working on 402\n"
     ]
    }
   ],
   "source": [
    "training_data = generate_training_data(object_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c69024eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./pickle/training_data_d006_c300.pk','wb') as f:\n",
    "    pickle.dump(training_data,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652f0d37",
   "metadata": {},
   "source": [
    "### Analyse Matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb30e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#subset_matches = {k: object_matches[k] for k in (5,11,13,14)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "26604d5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(training_data['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "55a5f729",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [ [1,10], [2,20], [3,30] ]\n",
    "c = ['dig','ten']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "8cd0fa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = dict(zip(c,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "04b40d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dig': (1, 2, 3), 'ten': (10, 20, 30)}"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(c,zip(*a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695f6ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
